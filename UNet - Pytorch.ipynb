{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the Dataset\n",
    "IMAGE_DIR = \"Dataset/2d_images/\"\n",
    "MASK_DIR = \"Dataset/2d_masks/\"\n",
    "with open('Dataset/Lung_CT_Dataset.csv','w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['filename', 'mask'])\n",
    "    \n",
    "    for p in os.listdir(IMAGE_DIR):\n",
    "        image_path = os.path.join(IMAGE_DIR, p)\n",
    "        mask_path = os.path.join(MASK_DIR, p)\n",
    "        writer.writerow([image_path, mask_path])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Dataset/Lung_CT_Dataset.csv\")\n",
    "data = data.iloc[np.random.permutation(len(data))]\n",
    "p = int(len(data)*0.7)\n",
    "train, validation = data[:p], data[p:]\n",
    "train.to_csv(\"Dataset/Lung_CT_Train.csv\", index=False)\n",
    "validation.to_csv(\"Dataset/Lung_CT_Validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from dataset import LungCTDataset\n",
    "lung_ct_train_dataset = LungCTDataset(csv_file='Dataset/Lung_CT_Train.csv', root_dir='./')\n",
    "lung_ct_val_dataset = LungCTDataset(csv_file='Dataset/Lung_CT_Validation.csv', root_dir='./')\n",
    "train_dataloader = DataLoader(lung_ct_train_dataset, batch_size=100, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(lung_ct_val_dataset, batch_size=100, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from model import * \n",
    "model_instance = UNet(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# model_instance.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model_instance.parameters(), lr=0.000001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for batch_idx, data in enumerate(train_dataloader):\n",
    "        data, target = Variable(data[\"image\"]), Variable(data[\"mask\"])\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(data.float())\n",
    "        loss = criterion(output.float(), target.float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1 == 0:\n",
    "            #print(loss.data)\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_dataloader.dataset),\n",
    "                100. * batch_idx / len(train_dataloader), loss.data)) # sangkny [0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for data in val_dataloader:\n",
    "        data, target = Variable(data[\"image\"], volatile=True), Variable(data[\"mask\"])\n",
    "        output = model(data.float())\n",
    "        # print(output.data[0]) # need to change output.data because of version changes\n",
    "        test_loss += criterion(output.float(), target.float()).data # [0] # sum up batch loss\n",
    "    test_loss /= len(val_dataloader.dataset)\n",
    "    print(\"Average Loss: \", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Train Epoch: 1 [0/185 (0%)]\tLoss: 0.892298\n",
      "Train Epoch: 1 [85/185 (50%)]\tLoss: 0.901305\n",
      "Average Loss:  tensor(0.0069)\n",
      "Train Epoch: 2 [0/185 (0%)]\tLoss: 0.900302\n",
      "Train Epoch: 2 [85/185 (50%)]\tLoss: 0.890575\n",
      "Average Loss:  tensor(0.0084)\n",
      "Train Epoch: 3 [0/185 (0%)]\tLoss: 0.893602\n",
      "Train Epoch: 3 [85/185 (50%)]\tLoss: 0.903235\n",
      "Average Loss:  tensor(0.0091)\n",
      "Train Epoch: 4 [0/185 (0%)]\tLoss: 0.892886\n",
      "Train Epoch: 4 [85/185 (50%)]\tLoss: 0.900117\n",
      "Average Loss:  tensor(0.0097)\n",
      "Train Epoch: 5 [0/185 (0%)]\tLoss: 0.892075\n",
      "Train Epoch: 5 [85/185 (50%)]\tLoss: 0.898867\n",
      "Average Loss:  tensor(0.0101)\n",
      "Train Epoch: 6 [0/185 (0%)]\tLoss: 0.891311\n",
      "Train Epoch: 6 [85/185 (50%)]\tLoss: 0.900516\n",
      "Average Loss:  tensor(0.0104)\n",
      "Train Epoch: 7 [0/185 (0%)]\tLoss: 0.899841\n",
      "Train Epoch: 7 [85/185 (50%)]\tLoss: 0.892044\n",
      "Average Loss:  tensor(0.0110)\n",
      "Train Epoch: 8 [0/185 (0%)]\tLoss: 0.900197\n",
      "Train Epoch: 8 [85/185 (50%)]\tLoss: 0.890548\n",
      "Average Loss:  tensor(0.0116)\n",
      "Train Epoch: 9 [0/185 (0%)]\tLoss: 0.891941\n",
      "Train Epoch: 9 [85/185 (50%)]\tLoss: 0.899284\n",
      "Average Loss:  tensor(0.0121)\n",
      "Train Epoch: 10 [0/185 (0%)]\tLoss: 0.900612\n",
      "Train Epoch: 10 [85/185 (50%)]\tLoss: 0.891159\n",
      "Average Loss:  tensor(0.0125)\n",
      "Train Epoch: 11 [0/185 (0%)]\tLoss: 0.898816\n",
      "Train Epoch: 11 [85/185 (50%)]\tLoss: 0.888763\n",
      "Average Loss:  tensor(0.0128)\n",
      "Train Epoch: 12 [0/185 (0%)]\tLoss: 0.898691\n",
      "Train Epoch: 12 [85/185 (50%)]\tLoss: 0.889993\n",
      "Average Loss:  tensor(0.0130)\n",
      "Train Epoch: 13 [0/185 (0%)]\tLoss: 0.891796\n",
      "Train Epoch: 13 [85/185 (50%)]\tLoss: 0.902108\n",
      "Average Loss:  tensor(0.0130)\n",
      "Train Epoch: 14 [0/185 (0%)]\tLoss: 0.900025\n",
      "Train Epoch: 14 [85/185 (50%)]\tLoss: 0.890421\n",
      "Average Loss:  tensor(0.0130)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 99 % validation accuracy \n",
    "for epoch in range(1, 15):\n",
    "    train(model_instance, epoch)\n",
    "    test(model_instance)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model_instance, './saved_models/mini_unet1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}